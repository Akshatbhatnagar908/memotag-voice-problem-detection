{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ee1627-f10f-4fb7-91f1-0aea14381b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the speech recognition library\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943c72e5-6979-452b-a8c7-fbdcdfd286e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "please help me Lag Gai help me\n"
     ]
    }
   ],
   "source": [
    "# Create a Recognizer instance to process audio input\n",
    "r=sr.Recognizer()\n",
    "\n",
    "# Use the default microphone as the audio source\n",
    "with sr.Microphone() as src:\n",
    "    print(\"Listening...\")# Notify user that the system is listening\n",
    "    audio = r.listen(src)# Listen for the first phrase and extract audio data\n",
    "    audio_input = r.recognize_google(audio)\n",
    "    print(audio_input)\n",
    "    audio_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cb028d-11bd-4c2b-ba29-953a9bc5c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pauses found at positions: [(5, ','), (18, '?'), (28, '.')]\n"
     ]
    }
   ],
   "source": [
    "# Function to find pauses based on punctuation in a sentence\n",
    "def find_pauses(sentence):\n",
    "    pauses = []# List to store positions of pauses\n",
    "    pause_chars = ['.', ',', '!', '?', ';', ':'] # Common punctuation indicating pauses\n",
    "     # Iterate through the sentence character by character\n",
    "    for i, char in enumerate(sentence):\n",
    "        if char in pause_chars:# If the character is a pause character\n",
    "            pauses.append((i, char)) # Add its position and character to the list\n",
    "\n",
    "    return pauses # Return the list of pauses found\n",
    "\n",
    "\n",
    "# Example usage of find_pauses function\n",
    "# Example usage\n",
    "sentence = \"Hello, how are you? I'm fine.\"\n",
    "pauses = find_pauses(sentence)\n",
    "print(\"Pauses found at positions:\", pauses) # Print the detected pauses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef8cbb2-1790-479a-b06c-9cb3d137a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected pauses at positions (between characters):\n",
      "Pause before ',' at position 5 (delay = 0.7s)\n",
      "Pause before 'o' at position 8 (delay = 0.6s)\n",
      "Pause before 'r' at position 12 (delay = 0.8s)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans# Import KMeans for clustering pauses or delays\n",
    "import numpy as np# Import KMeans for clustering pauses or delays\n",
    "\n",
    "# Simulated sentence and corresponding time delays between characters\n",
    "sentence = \"Hello, how are you?\"\n",
    "delays = [0.1, 0.1, 0.2, 0.3, 0.1, 0.7,  # \"Hello,\" # Delays after each character in \"Hello,\"# Delays in \" ho\"  # Delays in \"w are\"\n",
    "          0.1, 0.1, 0.6,                 # \" ho\"# Delays in \" ho\"  # Delays in \"w are\"\n",
    "          0.1, 0.2, 0.1, 0.8,            # \"w are\"  # Delays in \"w are\"\n",
    "          0.1, 0.1, 0.1, 0.1, 0.1]       # \" you?\" # Delays in \" you?\"\n",
    "\n",
    "# Convert to 2D array for sklearn\n",
    "X = np.array(delays).reshape(-1, 1)\n",
    "\n",
    "# Apply KMeans with 2 clusters: pause vs no-pause\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Determine which cluster represents pauses (the one with the higher average delay)\n",
    "cluster_means = [X[labels == i].mean() for i in range(2)]\n",
    "pause_cluster = np.argmax(cluster_means)\n",
    "\n",
    "# Print results\n",
    "print(\"Detected pauses at positions (between characters):\")\n",
    "for i, (char, delay, label) in enumerate(zip(sentence, delays, labels)):\n",
    "    if label == pause_cluster:\n",
    "        print(f\"Pause before '{char}' at position {i} (delay = {delay}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c8de86-d291-4ef5-9bbf-a7065ff5b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hesitation words found:\n",
      "'uhhh' at position 11\n",
      "'um' at position 32\n",
      "'ohh' at position 49\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a list of common hesitation words\n",
    "hesitation_words = ['uh', 'uhh', 'uhhh', 'um', 'umm', 'ummm', 'oh', 'ohh', 'ohhh', 'err', 'erm']\n",
    "\n",
    "# Compile a regex pattern that matches hesitation words (with optional repetition)\n",
    "pattern = re.compile(r'\\b(' + '|'.join(hesitation_words) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "def find_hesitation_words(sentence):\n",
    "    matches = list(pattern.finditer(sentence))\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        word = match.group()\n",
    "        position = match.start()\n",
    "        results.append((word, position))\n",
    "    return results\n",
    "\n",
    "# === Example Usage ===\n",
    "sentence = \"I was like uhhh maybe we could, um, try again or ohh just leave it.\"\n",
    "hesitations = find_hesitation_words(sentence)\n",
    "\n",
    "print(\"Hesitation words found:\")\n",
    "for word, pos in hesitations:\n",
    "    print(f\"'{word}' at position {pos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c81680d-d5f7-47da-8e13-e2a89f7c004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# Function to detect if an unexpected word is used in a sentence based on semantic similarity\n",
    "def detect_semantic_mismatch(sentence, expected_word, actual_word):\n",
    "    doc = nlp(sentence) # Process the sentence (not used further here, but may be useful for context)\n",
    "     # Calculate similarity between expected and actual word\n",
    "    sim = nlp(expected_word).similarity(nlp(actual_word))\n",
    "    # If similarity is too low, print a warning\n",
    "    if sim < 0.4:  # threshold based on context\n",
    "        print(f\"Potential word substitution: '{actual_word}' doesn't fit (expected something like '{expected_word}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdbc230e-86da-459d-a597-aa9da557aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak now!\n",
      "Recording finished.\n",
      "Mean Pitch: nan Hz\n",
      "Pitch Variation: ±nan Hz\n",
      "Speech Rate: 0.00 syllables/min\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd # Library to record audio from the microphone\n",
    "from scipy.io.wavfile import write # For saving recorded audio as WAV file\n",
    "import parselmouth # Interface to Praat for speech analysis\n",
    "from parselmouth.praat import call# Used to make Praat calls\n",
    "import numpy as np\n",
    "import tempfile# Used to create temporary files\n",
    "import os# For file management like deleting temp files\n",
    "\n",
    "# Function to record audio using the system microphone\n",
    "def record_audio(duration=5, fs=44100):\n",
    "    print(\"Recording... Speak now!\")# Prompt the user to begin speaking\n",
    "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')# Record audio\n",
    "    sd.wait() # Wait until recording is complete\n",
    "    print(\"Recording finished.\")  # Notify user that recording is done\n",
    "\n",
    "    temp_path = tempfile.mktemp(\".wav\")# Create a temporary WAV file path\n",
    "    write(temp_path, fs, audio)# Save the recorded audio to the WAV file\n",
    "    return temp_path # Return the file path for later use\n",
    "\n",
    "# Function to analyze speech properties using Praat via parselmouth\n",
    "def analyze_speech(file_path):\n",
    "    sound = parselmouth.Sound(file_path)# Load the audio file as a sound object\n",
    "\n",
    "    # Get pitch\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)# Extract pitch object\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\") # Compute the mean pitch over the entire sound\n",
    "    pitch_sd = call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\") # Compute standard deviation of pitch\n",
    "    \n",
    "    # Get pitch values\n",
    "    pitch_values = pitch.selected_array['frequency'] # Get the pitch values as a NumPy array\n",
    "    time_values = pitch.xs()  # Time intervals# Get the corresponding time stamps for the pitch value\n",
    "\n",
    "    # Count the number of pitch peaks (simple approximation for periods)\n",
    "    pitch_peaks = np.count_nonzero(pitch_values > 0)  # Count non-zero pitch values (as peaks)\n",
    "\n",
    "    duration = call(sound, \"Get total duration\")\n",
    "    \n",
    "    # Calculate speech rate based on pitch peaks (approximating syllables/min)\n",
    "    speech_rate = pitch_peaks / duration * 60  # syllables/min\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Mean Pitch: {mean_pitch:.2f} Hz\")\n",
    "    print(f\"Pitch Variation: ±{pitch_sd:.2f} Hz\")\n",
    "    print(f\"Speech Rate: {speech_rate:.2f} syllables/min\")\n",
    "\n",
    "# === Run it ===\n",
    "audio_path = record_audio(duration=5)  # record 5 seconds\n",
    "analyze_speech(audio_path)\n",
    "\n",
    "# Optionally delete the temp file\n",
    "os.remove(audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47dcb589-9f58-48d6-835f-f65d03341144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Function to detect hesitation before nouns based on delay threshold\n",
    "def find_pauses_before_nouns(sentence, delays):\n",
    "    doc = nlp(sentence) # Process the sentence with spaCy\n",
    "    for i, token in enumerate(doc): # Iterate over each token in the sentence\n",
    "        if token.pos_ == \"NOUN\" and delays[i] > 0.5:# Check if token is a noun and delay exceeds threshold\n",
    "            print(f\"Hesitation before noun '{token.text}' at word index {i} (delay: {delays[i]}s)\") # Log pause\n",
    "\n",
    "# Run hesitation detection on recognized text\n",
    "print(find_pauses_before_nouns(audio_input, delays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b57823d7-d73e-484c-991c-19bdd8a556d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please help me Lag Gai help me\n"
     ]
    }
   ],
   "source": [
    "# Function to determine if a sentence is potentially incomplete\n",
    "def is_sentence_incomplete(sentence):\n",
    "    doc = nlp(sentence)# Process the sentence with spaCy\n",
    "    last_token = doc[-1]# Get the last token in the sentence\n",
    "    if last_token.pos_ in [\"CCONJ\", \"ADP\", \"VERB\"]: # Check for potentially trailing off sentence\n",
    "        print(\"Sentence may be incomplete or trailing off.\")\n",
    "\n",
    "# Check if the recognized sentence is incomplete\n",
    "print(audio_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332ef711-9b64-4a6c-9819-e8463e840cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I lose my voice after extended conversations.</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The conversation flowed naturally and easily.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talking for too long makes my voice weak.</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I experience frequent voice breaks.</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No issues with speaking or clarity.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text    label\n",
       "0  I lose my voice after extended conversations.  problem\n",
       "1  The conversation flowed naturally and easily.   normal\n",
       "2      Talking for too long makes my voice weak.  problem\n",
       "3            I experience frequent voice breaks.  problem\n",
       "4            No issues with speaking or clarity.   normal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bag of words finding that a person in problem or not\n",
    "# Let's create a larger mock dataset to simulate more realistic voice problem detection\n",
    "import random\n",
    "import pandas as pd \n",
    "\n",
    "# Define mock sentence templates\n",
    "normal_sentences = [\n",
    "    \"Good morning, how can I help you today?\",\n",
    "    \"Everything is fine with my voice.\",\n",
    "    \"I spoke at the meeting and felt comfortable.\",\n",
    "    \"No issues with speaking or clarity.\",\n",
    "    \"My voice feels strong and stable.\",\n",
    "    \"I can talk for hours without strain.\",\n",
    "    \"Speech is smooth and effortless today.\",\n",
    "    \"I'm able to speak clearly without any pain.\",\n",
    "    \"I gave a presentation and it went well.\",\n",
    "    \"The conversation flowed naturally and easily.\"\n",
    "]\n",
    "\n",
    "problem_sentences = [\n",
    "    \"My throat hurts when I talk.\",\n",
    "    \"I feel a lot of strain while speaking.\",\n",
    "    \"Sometimes my voice becomes hoarse.\",\n",
    "    \"I experience frequent voice breaks.\",\n",
    "    \"Talking for too long makes my voice weak.\",\n",
    "    \"I often have to clear my throat mid-sentence.\",\n",
    "    \"There’s pain when I raise my voice.\",\n",
    "    \"My vocal cords feel irritated.\",\n",
    "    \"I lose my voice after extended conversations.\",\n",
    "    \"My speech sounds raspy and unclear.\"\n",
    "]\n",
    "\n",
    "# Generate mock data\n",
    "texts = normal_sentences * 5 + problem_sentences * 5  # 50 of each category\n",
    "labels = [\"normal\"] * 50 + [\"problem\"] * 50\n",
    "\n",
    "# Shuffle the dataset\n",
    "combined = list(zip(texts, labels))\n",
    "random.shuffle(combined)\n",
    "texts, labels = zip(*combined)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_mock = pd.DataFrame({'text': texts, 'label': labels})\n",
    "df_mock.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25163153-50b3-417f-b0b0-7e219e07edbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bag of Words Accuracy': 1.0,\n",
       " 'TF-IDF Accuracy': 1.0,\n",
       " 'TF-IDF Recommended': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the mock dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_mock['text'], df_mock['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Bag of Words pipeline\n",
    "bow_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the TF-IDF pipeline\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train and evaluate BoW model\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "bow_preds = bow_pipeline.predict(X_test)\n",
    "bow_report = classification_report(y_test, bow_preds, output_dict=True)\n",
    "\n",
    "# Train and evaluate TF-IDF model\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "tfidf_preds = tfidf_pipeline.predict(X_test)\n",
    "tfidf_report = classification_report(y_test, tfidf_preds, output_dict=True)\n",
    "\n",
    "# Extract accuracy for comparison\n",
    "bow_accuracy = bow_report[\"accuracy\"]\n",
    "tfidf_accuracy = tfidf_report[\"accuracy\"]\n",
    "\n",
    "{\n",
    "    \"Bag of Words Accuracy\": round(bow_accuracy, 2),\n",
    "    \"TF-IDF Accuracy\": round(tfidf_accuracy, 2),\n",
    "    \"TF-IDF Recommended\": tfidf_accuracy >= bow_accuracy\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61325342-6461-4b46-ab75-b69bbb1c2c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
